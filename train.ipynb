{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from encodec import EncodecModel\n",
    "from encodec.msstftd import MultiScaleSTFTDiscriminator\n",
    "import encodec.customAudioDataset as data\n",
    "from encodec.losses import total_loss, disc_loss\n",
    "from encodec.utils import convert_audio, save_audio\n",
    "from encodec.customAudioDataset import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 2\n",
    "sample_rate = 24000\n",
    "learning_rate = 0.01\n",
    "dataset_path = './dataset'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.CustomAudioDataset(dataset_folder=dataset_path, n_samples=20, sample_rate=sample_rate, tensor_cut=48000, extension='flac')\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncodecModel._get_model(target_bandwidths=[1.5, 3, 6, 12, 24], \n",
    "                                sample_rate=sample_rate, \n",
    "                                channels=1, causal=False, audio_normalize=False, segment=1.0).to(device)\n",
    "\n",
    "disc = MultiScaleSTFTDiscriminator(filters=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.8, 0.99))\n",
    "optimizer_disc = optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(epoch, optimizer, optimizer_disc, model, disc, dataset_loader, losses):\n",
    "    model.train()\n",
    "    disc.train()\n",
    "    data_length = len(dataset_loader)\n",
    "    epoch_loss_g = 0.0\n",
    "    epoch_loss_w = 0.0\n",
    "    epoch_loss_disc = 0.0\n",
    "    for i, input_wav in enumerate(dataset_loader):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_disc.zero_grad()\n",
    "        input_wav = input_wav.to(device)\n",
    "        output_wav, loss_w = model(input_wav)\n",
    "        logits_real, fmap_real = disc(input_wav)\n",
    "        logits_fake, fmap_fake = disc(output_wav)\n",
    "        \n",
    "        losses_g = total_loss(fmap_real, logits_fake, fmap_fake, input_wav, output_wav, sample_rate, device)\n",
    "        loss_g = 3 * losses_g['l_g'] + 3 * losses_g['l_feat'] + losses_g['l_t'] / 10 + losses_g['l_f']\n",
    "\n",
    "        logits_real, _ = disc(input_wav)\n",
    "        logits_fake, _ = disc(output_wav.detach())\n",
    "        loss_disc = disc_loss(logits_real, logits_fake)\n",
    "        \n",
    "        loss_w.backward(retain_graph=True)        \n",
    "        loss_g.backward()   \n",
    "        loss_disc.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        epoch_loss_g += loss_g.item()\n",
    "        epoch_loss_w += loss_w.item()\n",
    "        epoch_loss_disc += loss_disc.item()\n",
    "        \n",
    "    losses['loss_g'].append(epoch_loss_g / data_length)\n",
    "    losses['loss_w'].append(epoch_loss_w / data_length)\n",
    "    losses['loss_disc'].append(epoch_loss_disc / data_length)\n",
    "    \n",
    "    print(f'Epoch {epoch} | Loss_g: {losses[\"loss_g\"][-1]:.4f} | Loss_w: {losses[\"loss_w\"][-1]:.4f} | Loss_disc: {losses[\"loss_disc\"][-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'loss_g': [], 'loss_w': [], 'loss_disc': []}\n",
    "def train(n_epochs, optimizer, optimizer_disc, model, disc, dataset_loader):    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_one_step(epoch, optimizer, optimizer_disc, model, disc, dataset_loader, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
